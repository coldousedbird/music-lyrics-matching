{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "443dcc27-7de2-4d11-800a-f41986364860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 08:39:27.461211: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-29 08:39:27.467165: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-29 08:39:27.544051: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-29 08:39:29.501749: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "filename: pink floyd - Scarecrow.lrc\n",
      "type(audio_data) <class 'numpy.ndarray'>\n",
      "timestamps: [27.87, 32.45, 37.69, 49.93, 54.67, 60.46, 72.85, 77.73, 83.15, 94.74000000000001]\n",
      "1\n",
      "2\n",
      "3\n",
      "filename: creedence - Wrote A Song For Everyone.lrc\n",
      "type(audio_data) <class 'numpy.ndarray'>\n",
      "timestamps: [15.38, 23.8, 32.44, 40.7, 49.87, 54.06, 58.27, 63.47, 74.93, 83.5, 92.13, 100.3, 109.62, 113.83, 118.14, 123.44, 160.12, 164.16, 168.38, 173.56, 180.69, 189.17, 197.45, 205.88, 214.74, 219.12, 223.32, 228.48, 233.57, 237.74, 242.06, 247.15, 252.34, 256.4, 260.66, 265.71, 284.37]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Загрузка данных\u001b[39;00m\n\u001b[1;32m     55\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../data/short_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 56\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Разделение данных на обучающую и тестовую выборки\u001b[39;00m\n\u001b[1;32m     59\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 38\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(data_dir, max_length)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mid\u001b[39m)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 38\u001b[0m     max_length \u001b[38;5;241m=\u001b[39m \u001b[43miteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Дополнение данных до максимальной длины\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPREPARING DATA 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 27\u001b[0m, in \u001b[0;36miteration\u001b[0;34m(X, y, filename, max_length)\u001b[0m\n\u001b[1;32m     25\u001b[0m X\u001b[38;5;241m.\u001b[39mappend(audio_data)\n\u001b[1;32m     26\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(timestamps)\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maudio_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def iteration(X, y, filename, max_length):\n",
    "    if filename.endswith('.lrc') and os.path.exists(os.path.join(data_dir, filename[:-4] + '.mp3')):\n",
    "        \n",
    "        audio_path = os.path.join(data_dir, filename[:-4] + '.mp3')\n",
    "        lrc_path = os.path.join(data_dir, filename)\n",
    "        \n",
    "        audio = AudioSegment.from_file(audio_path)\n",
    "        audio_data = np.array(audio.get_array_of_samples(), dtype=np.float32)\n",
    "        audio_data = np.expand_dims(audio_data, axis=1)\n",
    "        print(\"type(audio_data)\", type(audio_data))\n",
    "        \n",
    "        with open(lrc_path, 'r') as f:\n",
    "            time_parts = [line.split(']')[0][1:].split(':') for line in f.readlines()]\n",
    "        timestamps = [float(parts[0]) * 3600 + float(parts[1]) * 60 + float(parts[2]) if len(parts) == 3 else float(parts[0]) * 60 + float(parts[1]) for parts in time_parts]\n",
    "        print('timestamps:', timestamps)\n",
    "        \n",
    "        X.append(audio_data)\n",
    "        y.append(timestamps)\n",
    "        return max(max_length, len(audio_data))\n",
    "\n",
    "    \n",
    "\n",
    "# Функция загрузки данных\n",
    "def load_data(data_dir, max_length=5000):\n",
    "    X, y = [], []\n",
    "    id = 0\n",
    "    for filename in os.listdir(data_dir):\n",
    "        print(id)\n",
    "        id +=1\n",
    "        max_length = iteration(X, y, filename, max_length)\n",
    "        \n",
    "    # Дополнение данных до максимальной длины\n",
    "    print(\"PREPARING DATA 1\")\n",
    "    X_padded = [np.pad(audio_data, ((0, max_length - len(audio_data)), (0, 0)), mode='constant') for audio_data in X]\n",
    "    y_padded = [np.pad(timestamps, (0, max_length - len(timestamps)), mode='constant') for timestamps in y]\n",
    "    X, y = np.array(X_padded), np.array(y_padded)\n",
    "\n",
    "    # Разбиение аудио на фрагменты и добавление в списки\n",
    "    print(\"PREPARING DATA 2\")\n",
    "    X = np.concatenate([np.expand_dims(segment, axis=1) for audio_data in X for segment in [audio_data[i:i+max_length] for i in range(0, len(audio_data), max_length)]], axis=0)\n",
    "    y = np.concatenate([segment_timestamps for timestamps in y for segment_timestamps in [timestamps[i:i+max_length] for i in range(0, len(timestamps), max_length)]], axis=0)\n",
    "    print(\"\\nX[0]:\", X[0])\n",
    "    print(\"\\nY[0]:\", y[0])\n",
    "    return X, y\n",
    "\n",
    "# Загрузка данных\n",
    "data_dir = '../../data/short_dataset'\n",
    "X, y = load_data(data_dir)\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# # Создание модели\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(256, input_shape=(None, 1), return_sequences=True))\n",
    "# model.add(Dropout(0.8))\n",
    "# model.add(LSTM(128, return_sequences=True))\n",
    "# model.add(Dropout(0.8))\n",
    "# model.add(LSTM(64, return_sequences=True))\n",
    "# model.add(Dropout(0.8))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1))\n",
    "# model.compile(optimizer=Adam(), loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# def data_generator(X, y, batch_size=32):\n",
    "#     while True:\n",
    "#         indices = np.random.randint(0, len(X), size=batch_size)\n",
    "#         yield X[indices], y[indices]\n",
    "\n",
    "# history = model.fit(data_generator(X_train, y_train, batch_size=32), steps_per_epoch=3000, epochs=10, validation_data=data_generator(X_test, y_test, batch_size=32), validation_steps=10)\n",
    "\n",
    "# # Оценка производительности модели на тестовых данных\n",
    "# test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "# print(f\"Test Loss: {test_loss:.4f}\")\n",
    "# print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# # Оценка производительности модели на тестовых данных\n",
    "# test_loss = model.evaluate(X_test, y_test)\n",
    "# print(f\"Test Loss: {test_loss:.4f}\")\n",
    "# # Сохранение модели\n",
    "# model.save('my_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c52b1050-cdfb-4875-9835-9b9eb42d9ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/ae/54/e70102a9c12d27d985ba659f336851732415e5a02864bef2ead36afaf15d/scikit_learn-1.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading scikit_learn-1.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/coldousedbird/.local/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Obtaining dependency information for scipy>=1.6.0 from https://files.pythonhosted.org/packages/88/ab/6ecdc526d509d33814835447bbbeedbebdec7cca46ef495a61b00a35b4bf/scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m610.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m454.4 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Obtaining dependency information for joblib>=1.2.0 from https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Obtaining dependency information for threadpoolctl>=3.1.0 from https://files.pythonhosted.org/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.0 scipy-1.13.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
